import os
import re
import string
import json
import time
import google.generativeai as genai
import pandas as pd
from sklearn.metrics import accuracy_score
from pydantic import BaseModel
from datetime import datetime
from dateutil.parser import parse as parse_date, ParserError

# gemini api config
# this needs to be generated by the user
genai.configure(api_key="")

generation_config = {
    "temperature": 0,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 8192
}

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    generation_config=generation_config,
)

chat_session = model.start_chat(history=[])

#load conversations
def load_json_file(file_path):
    with open(file_path, 'r') as f:
        conversations = json.load(f)
    return conversations

def query_gemini_for_info(conversation_data):
    conversation_text = "\n".join([f"{speaker}: {text}" for speaker, text in conversation_data])
    
    
    prompt = (
        f"Please extract the following information from this conversation: customer name, email, "
        f"order ID, and other details in JSON format from the following conversation:\n{conversation_text}"
    )
    
    
    response = chat_session.send_message(prompt)
    
    
    print("Gemini LLM response:", response.text)

    try:
        
        extracted_info = json.loads(response.text)
    except json.JSONDecodeError:
        print("Error: Unable to parse the response as JSON.")
        extracted_info = {}  
    
    return extracted_info



def normalize_value(value):
    """Normalize values for robust comparison."""
    if value in [None, [], 'Not Provided', 'None', 'null']:
        return 'Not Provided'

    value = str(value).strip()


    try:
        parsed_date = parse_date(value, fuzzy=True, default=datetime(1900, 1, 1))

        return parsed_date.strftime('%Y-%m')
    except (ParserError, ValueError, OverflowError):

        return clean_text(value)

def clean_text(text):
    """Lowercase and remove punctuation from text."""
    text = text.lower().translate(str.maketrans('', '', string.punctuation))
    return re.sub(r'\W+', ' ', text).strip()

def display_comparison_table(field_names, extracted_info, ground_truth_info):
    comparison_data = []
    accurate_count = 0

    for field in field_names:
        gt_value = ground_truth_info.get(field, 'Not Provided')
        extracted_value = extracted_info.get(field, 'Not Mentioned')


        normalized_gt = normalize_value(gt_value)
        normalized_extracted = normalize_value(extracted_value)

        
        accurate = 'Yes' if normalized_gt == normalized_extracted else 'No'

        comparison_data.append([field, gt_value, extracted_value, accurate])
        if accurate == 'Yes':
            accurate_count += 1


    field_accuracy = accurate_count / len(field_names) if field_names else 0.0

  
    df = pd.DataFrame(comparison_data, columns=["Field", "Ground Truth", "Extracted", "Accurate?"])
    print(df.to_string(index=False))
    print(f"Field Accuracy: {field_accuracy * 100:.2f}%\n")

    return field_accuracy



def evaluate_model_performance(conversations):
    field_names = ["customer_name", "email", "membership_level", "phone", "order_ID", "payment_method", "product_names", "purchase_date", "amounts"]
    field_accuracies = []

    for conversation in conversations:
        convo_id = conversation["convo_id"]
        ground_truth = conversation["scenario"]

        print(f"\n=== Conversation ID: {convo_id} ===")


        print("\nField Comparison:")

   
        extracted_info_str = conversation.get("extracted_info", "").strip()


        if extracted_info_str.startswith("```json"):
            extracted_info_str = extracted_info_str[7:-3].strip()

        if not extracted_info_str:
            print(f"Warning: No extracted info available for conversation ID {convo_id}")
            continue

        try:
            extracted_info = json.loads(extracted_info_str)
        except json.JSONDecodeError:
            print(f"Error: Failed to decode JSON for conversation ID {convo_id}. Skipping this conversation.")
            continue

        gt_personal = ground_truth.get("personal", {})
        gt_order = ground_truth.get("order", {})

    
        gt_combined = {**gt_personal, **gt_order}


        field_accuracy = display_comparison_table(field_names, extracted_info, gt_combined)

   
        field_accuracies.append(field_accuracy or 0.0)


    overall_field_accuracy = sum(field_accuracies) / len(field_accuracies) if field_accuracies else 0
    print(f"Overall Field Accuracy: {overall_field_accuracy * 100:.2f}%")

# if __name__ == "__main__":
#     file_path = "./abcd_sample.json"
#     conversations = load_json_file(file_path)

#     all_conversation_results = []

#     # Iterate over each conversation directly from the list
#     for conversation in conversations:
#         try:
#             print(f"\nProcessing Conversation ID: {conversation['convo_id']}")

#             extracted_info = query_gemini_for_info(conversation["original"], output_format="json")
#             print(f"Extracted Info: {extracted_info}")

#             conversation_result = {
#                 "convo_id": conversation['convo_id'],
#                 "extracted_info": extracted_info,
#                 "scenario": conversation["scenario"]
#             }
#             all_conversation_results.append(conversation_result)
#         except KeyError as e:
#             print(f"Error processing conversation: {e}")

#    
#     evaluate_model_performance(all_conversation_results)