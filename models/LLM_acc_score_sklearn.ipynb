{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "7oQo2nxJWfzj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_data(json_path):\n",
        "    with open(json_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "def extract_true_vals(data):\n",
        "    \"\"\"\n",
        "    Extract the true values (customer_name, email, phone) from the JSON data.\n",
        "    Returns list of dicts that are true values from the conversation\n",
        "    \"\"\"\n",
        "    true_vals = []\n",
        "    for i in data:\n",
        "        scenario = i.get('scenario', {})\n",
        "        personal_info = scenario.get('personal', {})\n",
        "        true_vals.append({\n",
        "            'customer_name': personal_info.get('customer_name', '').lower(),\n",
        "            'email': personal_info.get('email', '').lower(),\n",
        "            'phone': personal_info.get('phone', '').lower()\n",
        "        })\n",
        "    return true_vals\n",
        "\n",
        "def convert_to_comparable_format(vals):\n",
        "    \"\"\"\n",
        "    Convert a list of dicts to a list of tuples for comparison.\n",
        "    \"\"\"\n",
        "    return [(val['customer_name'], val['email'], val['phone']) for val in vals]\n",
        "\n",
        "def compare_and_display_results(y_true, y_pred, show_all=True, output_format='df'):\n",
        "    \"\"\"\n",
        "    Compare true and predicted values and display them either as df or json.\n",
        "    If show_all is True, shows all comparisons; otherwise, shows only mismatches.\n",
        "    \"\"\"\n",
        "    comparisons = []\n",
        "    for i, (true, pred) in enumerate(zip(y_true, y_pred)):\n",
        "        comparison = {\n",
        "            'Index': i + 1,\n",
        "            'True Customer Name': true[0],\n",
        "            'Predicted Customer Name': pred[0],\n",
        "            'True Email': true[1],\n",
        "            'Predicted Email': pred[1],\n",
        "            'True Phone': true[2],\n",
        "            'Predicted Phone': pred[2],\n",
        "            'Match': true == pred\n",
        "        }\n",
        "        comparisons.append(comparison)\n",
        "\n",
        "    df_comparisons = pd.DataFrame(comparisons)\n",
        "\n",
        "    if show_all == False : df_comparisons = df_comparisons[~df_comparisons['Match']]\n",
        "\n",
        "    # df or json\n",
        "    if output_format == 'df':\n",
        "        return tabulate(df_comparisons, headers='keys', tablefmt='grid')\n",
        "    elif output_format == 'json':\n",
        "        return df_comparisons.to_json(orient='records', indent=2)\n",
        "\n",
        "def test_llm_predictions(json_path, llm_predictions, show_all=True):\n",
        "    \"\"\"\n",
        "    Run all methods.\n",
        "    Arg llm_predictions is a list of dicts.\n",
        "    Returns float accuracy score of LLM using sklearn's accuracy_score for each conversation.\n",
        "    \"\"\"\n",
        "    data = load_json_data(json_path)\n",
        "    true_vals = extract_true_vals(data)\n",
        "\n",
        "    # Convert true values and predictions to comparable formats\n",
        "    y_true = convert_to_comparable_format(true_vals)\n",
        "    y_pred = convert_to_comparable_format(llm_predictions)\n",
        "\n",
        "    # Calc accuracy for each conversation\n",
        "    conversation_accuracy = [1 if true == pred else 0 for true, pred in zip(y_true, y_pred)]\n",
        "\n",
        "    # If all elems are 1, all preds are correct. use accuracy_score to calc acc_score\n",
        "    acc_score = accuracy_score([1] * len(conversation_accuracy), conversation_accuracy)\n",
        "\n",
        "    # Display results\n",
        "    results = compare_and_display_results(y_true, y_pred, show_all, output_format='json') # If you want json/df, change here\n",
        "\n",
        "    return acc_score, results"
      ],
      "metadata": {
        "id": "ukZcvegnWhSV"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to main json file within your specific Google Drive, please mount GDrive\n",
        "json_file_path = '/content/drive/MyDrive/abcd_sample.json'\n",
        "\n",
        "# LLM predictions (used sample, for testing reasons)\n",
        "# Paste your results here?\n",
        "llm_predictions = [\n",
        "    {'customer_name': 'crystal minh', 'email': 'cminh730@email.com', 'phone': '(977) 625-2661'},\n",
        "    {'customer_name': 'alessandro phoenix', 'email': 'incorrectemail@gmail.com', 'phone': '(727) 760-7806'},\n",
        "    {'customer_name': 'joyce wu', 'email': '', 'phone': '(859) 787-9085'},\n",
        "]\n",
        "\n",
        "# Test LLM predictions against the ground truth with a detailed view of mismatches\n",
        "acc_score, results = test_llm_predictions(json_file_path, llm_predictions, show_all=False) # If you want to see each comparison, change show_all to true\n",
        "\n",
        "print(f\"\\nLLM Prediction Accuracy: {acc_score}%\")\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9LC-rRlWlW0",
        "outputId": "219e54e9-5ed3-4165-f36c-cedd53196e56"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LLM Prediction Accuracy: 0.6666666666666666%\n",
            "[\n",
            "  {\n",
            "    \"Index\":2,\n",
            "    \"True Customer Name\":\"alessandro phoenix\",\n",
            "    \"Predicted Customer Name\":\"alessandro phoenix\",\n",
            "    \"True Email\":\"aphoenix939@email.com\",\n",
            "    \"Predicted Email\":\"incorrectemail@gmail.com\",\n",
            "    \"True Phone\":\"(727) 760-7806\",\n",
            "    \"Predicted Phone\":\"(727) 760-7806\",\n",
            "    \"Match\":false\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pQsEYE69XW-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}